{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanisms to Query SQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Notebook demostrates LlamaIndex's capabilities to work with SQL Databases. \n",
    "We will use a MySQL table to perform a number of queries. \n",
    "- Create the SQL connection and craete an engine object to connect to the MySQL DB (DB Name: demo_db, table name: walmart). \n",
    "- An SQL Database object is also created.\n",
    "- We will refer to the walmart table which contains weekly sales volumes and a host of other parameters - CPI, Fuel price, Temparature, holiday or not, etc. \n",
    "- We will use three mechanisms to perform queries on the table. \n",
    "- <b>Part 1: Use the NLSQLQueryEngine that converts a natural language query into the corresponding SQL query and fetches the result</b>\n",
    "- <b>Part 2: Use the SQLTableRetrieverQueryEngine to perform the same operation. This method also uses an intermediate VectorStore</b>\n",
    "- <b>Part 3: Use the NLSQLRetriever and plug in the retrieved documents (k=n mentioned) into RetreiverQueryEngine to articulate the final outcome</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mCourtesy Notice\u001b[0m: Pipenv found itself running within a virtual environment, so it will automatically use that environment, instead of creating its own for any project. You can set \u001b[1mPIPENV_IGNORE_VIRTUALENVS=1\u001b[0m to force pipenv to ignore that environment and create its own instead. You can set \u001b[1mPIPENV_VERBOSITY=-1\u001b[0m to suppress this warning.\n",
      "\u001b[1;32mInstalling llama-index\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[?25lResolving llama-index\u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Installation Succeeded\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Installing llama-index...\n",
      "\u001b[1A\u001b[2K\u001b[1;32mInstalling pymysql\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[?25lResolving pymysql\u001b[33m...\u001b[0m\n",
      "\u001b[2K\u001b[1mAdded \u001b[0m\u001b[1;32mpymysql\u001b[0m to Pipfile's \u001b[1;33m[\u001b[0m\u001b[33mpackages\u001b[0m\u001b[1;33m]\u001b[0m \u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Installation Succeededl...\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Installing pymysql...\n",
      "\u001b[1A\u001b[2K\u001b[1;33mPipfile.lock \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m2fd4f0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m out of date: run `pipfile lock` to update to \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m83cf46\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[1mRunning\u001b[0m \u001b[33m\u001b[1m$ pipenv lock\u001b[0m \u001b[1mthen\u001b[0m \u001b[33m\u001b[1m$ pipenv sync\u001b[0m\u001b[1m.\u001b[0m\n",
      "Locking\u001b[0m \u001b[33m[packages]\u001b[0m dependencies...\u001b[0m\n",
      "\u001b[?25lBuilding requirements\u001b[33m...\u001b[0m\n",
      "\u001b[2KResolving dependencies\u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Success! Locking packages...\n",
      "\u001b[2K\u001b[32m⠏\u001b[0m Locking packages...\n",
      "\u001b[1A\u001b[2KLocking\u001b[0m \u001b[33m[dev-packages]\u001b[0m dependencies...\u001b[0m\n",
      "\u001b[?25lBuilding requirements\u001b[33m...\u001b[0m\n",
      "\u001b[2KResolving dependencies\u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Success! Locking dev-packages...\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Locking dev-packages...\n",
      "\u001b[1A\u001b[2K\u001b[1mUpdated Pipfile.lock (683d75eb62d303be113c10b5f500615697184aa044654c5796288519e483cf46)!\u001b[0m\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1m(\u001b[0m\u001b[1m83cf46\u001b[0m\u001b[1m)\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[32mAll dependencies are now up-to-date!\u001b[0m\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1m(\u001b[0m\u001b[1m83cf46\u001b[0m\u001b[1m)\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[32mCourtesy Notice\u001b[0m: Pipenv found itself running within a virtual environment, so it will automatically use that environment, instead of creating its own for any project. You can set \u001b[1mPIPENV_IGNORE_VIRTUALENVS=1\u001b[0m to force pipenv to ignore that environment and create its own instead. You can set \u001b[1mPIPENV_VERBOSITY=-1\u001b[0m to suppress this warning.\n",
      "\u001b[1;32mInstalling ipython\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[?25lResolving ipython\u001b[33m...\u001b[0m\n",
      "\u001b[2K\u001b[1mAdded \u001b[0m\u001b[1;32mipython\u001b[0m to Pipfile's \u001b[1;33m[\u001b[0m\u001b[33mpackages\u001b[0m\u001b[1;33m]\u001b[0m \u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Installation Succeededn...\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Installing ipython...\n",
      "\u001b[1A\u001b[2K\u001b[1;33mPipfile.lock \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m83cf46\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m out of date: run `pipfile lock` to update to \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33me8fc3b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[1mRunning\u001b[0m \u001b[33m\u001b[1m$ pipenv lock\u001b[0m \u001b[1mthen\u001b[0m \u001b[33m\u001b[1m$ pipenv sync\u001b[0m\u001b[1m.\u001b[0m\n",
      "Locking\u001b[0m \u001b[33m[packages]\u001b[0m dependencies...\u001b[0m\n",
      "\u001b[?25lBuilding requirements\u001b[33m...\u001b[0m\n",
      "\u001b[2KResolving dependencies\u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Success! Locking packages...\n",
      "\u001b[2K\u001b[32m⠙\u001b[0m Locking packages...\n",
      "\u001b[1A\u001b[2KLocking\u001b[0m \u001b[33m[dev-packages]\u001b[0m dependencies...\u001b[0m\n",
      "\u001b[?25lBuilding requirements\u001b[33m...\u001b[0m\n",
      "\u001b[2KResolving dependencies\u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Success! Locking dev-packages...\n",
      "\u001b[2K\u001b[32m⠹\u001b[0m Locking dev-packages...\n",
      "\u001b[1A\u001b[2K\u001b[1mUpdated Pipfile.lock (d5bbb90b158ccc599937a0b8752669f6b1f4da6bda890087eb88cf0c2ce8fc3b)!\u001b[0m\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1m(\u001b[0m\u001b[1me8fc3b\u001b[0m\u001b[1m)\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[32mAll dependencies are now up-to-date!\u001b[0m\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1m(\u001b[0m\u001b[1me8fc3b\u001b[0m\u001b[1m)\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[32mCourtesy Notice\u001b[0m: Pipenv found itself running within a virtual environment, so it will automatically use that environment, instead of creating its own for any project. You can set \u001b[1mPIPENV_IGNORE_VIRTUALENVS=1\u001b[0m to force pipenv to ignore that environment and create its own instead. You can set \u001b[1mPIPENV_VERBOSITY=-1\u001b[0m to suppress this warning.\n",
      "\u001b[1;32mInstalling llama-index-embeddings-openai\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[?25lResolving llama-index-embeddings-openai\u001b[33m...\u001b[0m\n",
      "\u001b[2K\u001b[1mAdded \u001b[0m\u001b[1;32mllama-index-embeddings-openai\u001b[0m to Pipfile's \u001b[1;33m[\u001b[0m\u001b[33mpackages\u001b[0m\u001b[1;33m]\u001b[0m \u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Installation Succeededindex-embeddings-openai...\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Installing llama-index-embeddings-openai...\n",
      "\u001b[1A\u001b[2K\u001b[1;33mPipfile.lock \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33me8fc3b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m out of date: run `pipfile lock` to update to \u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m1460a3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[1mRunning\u001b[0m \u001b[33m\u001b[1m$ pipenv lock\u001b[0m \u001b[1mthen\u001b[0m \u001b[33m\u001b[1m$ pipenv sync\u001b[0m\u001b[1m.\u001b[0m\n",
      "Locking\u001b[0m \u001b[33m[packages]\u001b[0m dependencies...\u001b[0m\n",
      "\u001b[?25lBuilding requirements\u001b[33m...\u001b[0m\n",
      "\u001b[2KResolving dependencies\u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Success! Locking packages...\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Locking packages...\n",
      "\u001b[1A\u001b[2KLocking\u001b[0m \u001b[33m[dev-packages]\u001b[0m dependencies...\u001b[0m\n",
      "\u001b[?25lBuilding requirements\u001b[33m...\u001b[0m\n",
      "\u001b[2KResolving dependencies\u001b[33m...\u001b[0m\n",
      "\u001b[2K✔ Success! Locking dev-packages...\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Locking dev-packages...\n",
      "\u001b[1A\u001b[2K\u001b[1mUpdated Pipfile.lock (52723cace2e1e2baf11755590f7d6f5baaf062db75c3579fcb8db1a8ca1460a3)!\u001b[0m\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1m(\u001b[0m\u001b[1m1460a3\u001b[0m\u001b[1m)\u001b[0m\u001b[1;33m...\u001b[0m\n",
      "\u001b[32mAll dependencies are now up-to-date!\u001b[0m\n",
      "To activate this project's virtualenv, run \u001b[33mpipenv shell\u001b[0m.\n",
      "Alternatively, run a command inside the virtualenv with \u001b[33mpipenv run\u001b[0m.\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1m(\u001b[0m\u001b[1m1460a3\u001b[0m\u001b[1m)\u001b[0m\u001b[1;33m...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install the following Libraries if they are not already installed in your environment.\n",
    "\n",
    "!pipenv install llama-index pymysql -q\n",
    "!pipenv install ipython\n",
    "!pipenv install llama-index-embeddings-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLAlchemy is the Python SQL toolkit and Object Relational Mapper that gives \n",
    "# application developers the full power and flexibility of working with SQL databases and tables.\n",
    "\n",
    "from sqlalchemy import (\n",
    "    create_engine,               #API interface to work with SQL databases\n",
    "    text, \n",
    ")\n",
    "from llama_index.core import SQLDatabase\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Connection to Local Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the connection string \n",
    "\n",
    "db_user = \"root\"\n",
    "db_password = \"wahaj123\"\n",
    "db_host = \"localhost:3306\"\n",
    "db_name = \"demo_db\" #sampleDB\n",
    "\n",
    "connection_string = f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Database Through Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing three rows:\n",
      "(1, datetime.date(2005, 2, 10), 1643690.0, 0, 42.31, 2.572, 211.096, 8.106)\n",
      "(1, datetime.date(2012, 2, 10), 1641960.0, 1, 38.51, 2.548, 211.242, 8.106)\n",
      "(1, datetime.date(2019, 2, 10), 1611970.0, 0, 39.93, 2.514, 211.289, 8.106)\n",
      "Printing Table structure:\n",
      "('Store', 'int', 'NO', '', None, '')\n",
      "('Date', 'date', 'NO', '', None, '')\n",
      "('Weekly_Sales', 'float', 'YES', '', None, '')\n",
      "('Holiday_Flag', 'tinyint', 'YES', '', None, '')\n",
      "('Temperature', 'float', 'YES', '', None, '')\n",
      "('Fuel_Price', 'float', 'YES', '', None, '')\n",
      "('CPI', 'float', 'YES', '', None, '')\n",
      "('Unemployment', 'float', 'YES', '', None, '')\n"
     ]
    }
   ],
   "source": [
    "# Create an engine instance - The Engine is a factory in SQL Alchemy that can create new database connections\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Test the connection using raw SQL\n",
    "print(\"Printing three rows:\")\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"select * from walmart limit 3\"))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "        \n",
    "print(\"Printing Table structure:\")\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"describe walmart\"))\n",
    "    for row in result:\n",
    "        print(row)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setiing up LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "llm = OpenAI(temperature=0.1, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we define our SQLDatabase abstraction (a light wrapper around SQLAlchemy)\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"walmart\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Text-to-SQL Query Engine\n",
    "Once we have constructed our SQL database, we can use the NLSQLTableQueryEngine to construct natural language queries that are synthesized into SQL queries.\n",
    "Note that we need to specify the tables we want to use with this query engine. If we don't the query engine will pull all the schema context, \n",
    "which could overflow the context window of the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NLSQLTableQueryEngince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 unique stores in the dataset.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "\n",
    "query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database, tables=[\"walmart\"], llm=llm\n",
    ")\n",
    "query_str = \"How many unique stores are there?\"\n",
    "#query_str = \"What is the average CPI of each Store? Order the results by Store number.\"\n",
    "response = query_engine.query(query_str)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Query-Time Retrieval of Tables for Text-to-SQL\n",
    "If we don't know ahead of time which table we would like to use, and the total size of the table schema overflows your context window size, \n",
    "we should store the table schema in an index so that during query time we can retrieve the right schema.\n",
    "The way we can do this is using the SQLTableNodeMapping object, which takes in a SQLDatabase and produces a Node object \n",
    "for each SQLTableSchema object passed into the ObjectIndex constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.struct_store.sql_query import (\n",
    "    SQLTableRetrieverQueryEngine,\n",
    ")\n",
    "from llama_index.core.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "from llama_index.core import VectorStoreIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Storing the data in llamaindex vectore store named obj_index to store data as vectors using the SQLTableNodeMapping & SQLTableSchema modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = [\n",
    "    (SQLTableSchema(table_name=\"walmart\"))\n",
    "]  # add a SQLTableSchema for our table, you may add more tables here\n",
    "\n",
    "# The ObjectIndex class allows for the indexing of arbitrary Python objects including SQL database schema objects. \n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    table_schema_objs, \n",
    "    table_node_mapping,\n",
    "   index_cls=VectorStoreIndex,\n",
    ")\n",
    "query_engine = SQLTableRetrieverQueryEngine(\n",
    "    sql_database, obj_index.as_retriever(similarity_top_k=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average CPI for each store, ordered by store number, is as follows:\n",
      "Store 1: 215.99\n",
      "Store 2: 215.65\n",
      "Store 3: 219.39\n",
      "Store 4: 128.68\n",
      "Store 5: 216.57\n",
      "Store 6: 217.55\n",
      "Store 7: 193.66\n",
      "Store 8: 219.44\n",
      "Store 9: 219.63\n",
      "Store 10: 128.68\n",
      "Store 11: 219.39\n",
      "Store 12: 128.68\n",
      "Store 13: 128.68\n",
      "Store 14: 186.29\n",
      "Store 15: 135.09\n",
      "Store 16: 193.66\n",
      "Store 17: 128.68\n",
      "Store 18: 135.09\n",
      "Store 19: 135.09\n",
      "Store 20: 209.04\n",
      "Store 21: 215.65\n",
      "Store 22: 139.01\n",
      "Store 23: 135.09\n",
      "Store 24: 135.09\n",
      "Store 25: 209.04\n",
      "Store 26: 135.09\n",
      "Store 27: 139.01\n",
      "Store 28: 128.68\n",
      "Store 29: 135.09\n",
      "Store 30: 215.65\n",
      "Store 31: 215.65\n",
      "Store 32: 193.66\n",
      "Store 33: 128.68\n",
      "Store 34: 128.68\n",
      "Store 35: 139.01\n",
      "Store 36: 214.73\n",
      "Store 37: 214.73\n",
      "Store 38: 128.68\n",
      "Store 39: 214.73\n",
      "Store 40: 135.09\n",
      "Store 41: 193.66\n",
      "Store 42: 128.68\n",
      "Store 43: 207.74\n",
      "Store 44: 128.68\n",
      "Store 45: 186.29\n"
     ]
    }
   ],
   "source": [
    "query_str = \"What is the average CPI of each Store? Order the results by Store number.\"\n",
    "response = query_engine.query(query_str)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Text-to-SQL Retriever\n",
    "So far our text-to-SQL capability is packaged in a query engine and consists of both retrieval and synthesis.\n",
    "You can use the SQL retriever on its own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import NLSQLRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default retrieval (return_raw=True)\n",
    "nl_sql_retriever = NLSQLRetriever(\n",
    "    sql_database, tables=[\"walmart\"], return_raw=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Plug into our RetrieverQueryEngine\n",
    "We compose our SQL Retriever with our standard RetrieverQueryEngine to synthesize a response. The result is roughly similar to our packaged Text-to-SQL query engines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(nl_sql_retriever)\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What is the average CPI of each Store? Order the results by Store number.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average CPI of each Store, ordered by Store number, is as follows:\n",
      "Store 1: 215.9968736555193\n",
      "Store 2: 215.64630052259753\n",
      "Store 3: 219.39155258498826\n",
      "Store 4: 128.67968541925603\n",
      "Store 5: 216.56554524881855\n",
      "Store 6: 217.5531957666357\n",
      "Store 7: 193.6642447518302\n",
      "Store 8: 219.4390840330324\n",
      "Store 9: 219.62671303915812\n",
      "Store 10: 128.67968541925603\n",
      "Store 11: 219.39155258498826\n",
      "Store 12: 128.67968541925603\n",
      "Store 13: 128.67968541925603\n",
      "Store 14: 186.28567867679195\n",
      "Store 15: 135.09259502704327\n",
      "Store 16: 193.6642447518302\n",
      "Store 17: 128.67968541925603\n",
      "Store 18: 135.09259502704327\n",
      "Store 19: 135.09259502704327\n",
      "Store 20: 209.0381398234334\n",
      "Store 21: 215.64630052259753\n",
      "Store 22: 139.01129395811708\n",
      "Store 23: 135.09259502704327\n",
      "Store 24: 135.09259502704327\n",
      "Store 25: 209.0381398234334\n",
      "Store 26: 135.09259502704327\n",
      "Store 27: 139.01129395811708\n",
      "Store 28: 128.67968541925603\n",
      "Store 29: 135.09259502704327\n",
      "Store 30: 215.64630052259753\n",
      "Store 31: 215.64630052259753\n",
      "Store 32: 193.6642447518302\n",
      "Store 33: 128.67968541925603\n",
      "Store 34: 128.67968541925603\n",
      "Store 35: 139.01129395811708\n",
      "Store 36: 214.72903527746666\n",
      "Store 37: 214.72903527746666\n",
      "Store 38: 128.67968541925603\n",
      "Store 39: 214.72903527746666\n",
      "Store 40: 135.09259502704327\n",
      "Store 41: 193.6642447518302\n",
      "Store 42: 128.67968541925603\n",
      "Store 43: 207.7351400735495\n",
      "Store 44: 128.67968541925603\n",
      "Store 45: 186.28567867679195\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Demo-Folder-s2cjiHJX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
